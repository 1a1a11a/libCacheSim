//
// Created by Juncheng Yang on 10/3/20.
//

#include "bulkChainHashTable.h"
#include "../../include/libCacheSim/logging.h"
#include "../../include/libCacheSim/request.h"
#include "../../include/libCacheSim/cacheObj.h"
#include "hashtableStruct.h"
#include <assert.h>
#include <stdbool.h>

#include <stdlib.h>
#include <sys/mman.h>
#include <sysexits.h>
#include <x86intrin.h>


#define CACHE_ALIGN_SIZE                    64

/* the number of slots in one bucket array,
 * need to be multiple of 8 to make use of 64-byte cache line */
#define N_SLOT_PER_BUCKET                   8u
#define N_SLOT_PER_BUCKET_IN_BITS           3u

static __thread __uint128_t g_lehmer64_state = 1;

#define HASHSIZE(_n)        (1ULL << (_n))
#define HASHMASK(_n)        (HASHSIZE(_n) - 1)

#define CAL_HV(key, klen)   _get_hv_xxhash(key, klen)
#define GET_BUCKET(hv)      (&hash_table.table[((hv) & hash_table.hash_mask)])

#define GET_BUCKET_CHAIN_LEN(bucket_ptr)                                       \
                (((*(bucket_ptr)) & BUCKET_CHAIN_LEN_MASK) >> 48ul)
#define INCR_BUCKET_CHAIN_LEN(bucket_ptr)                                      \
                ((*(bucket_ptr)) += 0x0001000000000000ul)


static inline bool
_same_item(const char *key, uint32_t klen, uint64_t item_info) {
  struct item *oit = _info_to_item(item_info);
  return ((oit->klen == klen) && cc_memcmp(item_key(oit), key, klen) == 0);
}

static inline uint64_t
_build_item_info(uint64_t tag, uint64_t obj_idx1, uint64_t obj_idx2) {
  uint64_t item_info = 0;

  return item_info;
}

static inline uint64_t prand(void) {
  g_lehmer64_state *= 0xda942042e4dd58b5;
  return (uint64_t) g_lehmer64_state;
//    return g_lehmer64_state >> 64u;
}


hashtable_t *create_bulk_chaining_hashtable(const uint16_t hashpower) {
  hashtable_t *hashtable = my_malloc(hashtable_t);
  memset(hashtable, 0, sizeof(hashtable_t));
  hashtable->hashpower = hashpower;
  hashtable->btable = my_malloc_n(uint64_t, hashsize(hashtable->hashpower));
#if defined(USE_HUGEPAGE) && defined(MADV_HUGEPAGE)
  madvise(hashtable->table, sizeof(uint64_t)*hashsize(hashtable->hashpower), MADV_HUGEPAGE);
#endif
  if (hashtable->btable == NULL) {
    ERROR("unable to allocate hash table (size %llu)\n",
          (unsigned long long) sizeof(cache_obj_t)
              * hashsize(hashtable->hashpower));
    abort();
  }
  memset(hashtable->btable, 0, hashsize(hashpower) * sizeof(uint64_t));
  hashtable->n_cur_item = 0;
  return hashtable;
}

void free_bulk_chaining_hashtable(hashtable_t *hashtable) {
  my_free(sizeof(uint64_t) * hashsize(hashtable->hashpower, hashtable->btable);
  my_free(sizeof(hashtable_t), hashtable);
}

static inline uint64_t _get_hv_xxhash(const char *key, size_t klen) {
  return XXH3_64bits(key, klen);

  /* maybe this API is preferred
   *   uint64_t hv = XXH3_64bits_dispatch(key, klen);
   */
}

cache_obj_t *bulk_chaining_hashtable_insert(hashtable_t *hashtable, request_t *req) {
  if (hashtable->n_cur_item > (uint64_t) (hashsize(hashtable->hashpower) * 1.2))
    _bulk_chaining_hashtable_expand(hashtable);

  uint64_t hv = get_hash_value_int_64(&req->obj_id);
  uint64_t tag = CAL_TAG_FROM_HV(hv);

  cache_obj_t *cache_obj = &hashtable->table[hv];
  if (OBJ_EMPTY(cache_obj)) {
    // this place is available
    copy_request_to_cache_obj(cache_obj, req);
  } else {
    // this place is occupied, create a new cache_obj struct, linked to the end of chain
    cache_obj_t *new_cache_obj = create_cache_obj_from_request(req);
    while (cache_obj->hash_next) {
      cache_obj = cache_obj->hash_next;
    }
    cache_obj->hash_next = new_cache_obj;
    cache_obj = new_cache_obj;
  }
  hashtable->n_cur_item += 1;
  return cache_obj;



  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;

  /* 16-bit tag, 24-bit cache_obj_idx1, 24-bit cache_obj_idx2 */
  uint64_t item_info, insert_item_info;
  cache_obj_t *cache_obj =
  insert_item_info = _build_item_info(tag, obj_idx1, obj_idx2);

  int bkt_chain_len = GET_BUCKET_CHAIN_LEN(first_bkt);
  int n_item_slot;
  do {
    /* the last slot will be a pointer to the next
     * bucket if there is next bucket */
    for (int i = 0; i < N_SLOT_PER_BUCKET - 1; i++) {
      if (bkt[i] == 0) {
        bkt[i] = insert_item_info;
      }

        continue;
      }
      /* a potential hit */
      if (!_same_item(key, klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }

      /* found the item, now atomic update (or delete if already inserted)
       * x86 read and write 8-byte is always atomic */
      bkt[i] = insert_item_info;
      insert_item_info = 0;

      _item_free(item_info, false);

#ifdef OPTIMIZE_PMEM
      goto finish;
#endif
    }

#ifdef OPTIMIZE_PMEM
    if (insert_item_info == 0) {
        /* item has been inserted, do not check next array */
        goto finish;
    }
#endif
    bkt_chain_len -= 1;
    if (bkt_chain_len >= 0) {
      bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
    }
  } while (bkt_chain_len >= 0);

  /* we have searched every array, but have not found the old item
   * nor inserted new item - so we need to allocate a new array,
   * this is very rare */
  INCR(seg_metrics, hash_array_alloc);

  uint64_t *new_array = cc_zalloc(sizeof(uint64_t) * N_SLOT_PER_BUCKET);
  /* move the last item from last bucket to new bucket */
  new_array[0] = bkt[N_SLOT_PER_BUCKET - 1];
  new_array[1] = insert_item_info;
  insert_item_info = 0;

  __atomic_thread_fence(__ATOMIC_RELEASE);

  bkt[N_SLOT_PER_BUCKET - 1] = (uint64_t) new_array;

  INCR_BUCKET_CHAIN_LEN(first_bkt);
  ASSERT(GET_BUCKET_CHAIN_LEN(first_bkt) <= 8);

  finish:
  ASSERT(insert_item_info == 0);
  unlock_and_update_cas(first_bkt);
}

bool
hashtable_delete(const char *key, const uint32_t klen) {
  INCR(seg_metrics, hash_remove);

  bool deleted = false;

  uint64_t hv = CAL_HV(key, klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;

  uint64_t item_info;

  lock(first_bkt);

  int bkt_chain_len = GET_BUCKET_CHAIN_LEN(first_bkt);
  int n_item_slot;
  do {
    n_item_slot = bkt_chain_len > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < n_item_slot; i++) {
      if (bkt == first_bkt && i == 0) {
        continue;
      }

      item_info = bkt[i];
      if (GET_TAG(item_info) != tag) {
        continue;
      }
      /* a potential hit */
      if (!_same_item(key, klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }
      /* found the item, now delete */
      /* if this is the first and most up-to-date hash table entry
       * for this key, we need to mark tombstone */
      _item_free(item_info, !deleted);
      bkt[i] = 0;

      deleted = true;
    }
    bkt_chain_len -= 1;
    bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
  } while (bkt_chain_len >= 0);

  unlock(first_bkt);
  return deleted;
}

/*
 * the difference between delete and evict is that
 * delete needs to mark tombstone on the most recent object,
 * evict  does not need to mark tombstone if the item being evicted is not
 *          up to date, otherwise, it needs to mark tombstone on the second
 *          most recent object
 *
 */
bool
hashtable_evict(const char *oit_key, const uint32_t oit_klen,
                const uint64_t seg_id, const uint64_t offset) {
  INCR(seg_metrics, hash_remove);

  uint64_t hv = CAL_HV(oit_key, oit_klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;

  uint64_t item_info;
  uint64_t oit_info = _build_item_info(tag, seg_id, offset);

  bool first_match = true, item_outdated = true, fount_oit = false;

  lock(first_bkt);

  int bkt_chain_len = GET_BUCKET_CHAIN_LEN(first_bkt);
  int n_item_slot;
  do {
    n_item_slot = bkt_chain_len > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < n_item_slot; i++) {
      if (bkt == first_bkt && i == 0) {
        continue;
      }

      item_info = CLEAR_FREQ(bkt[i]);
      if (GET_TAG(item_info) != tag) {
        continue;
      }
      /* a potential hit */
      if (!_same_item(oit_key, oit_klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }

      if (first_match) {
        if (oit_info == item_info) {
          _item_free(item_info, false);
          bkt[i] = 0;
          item_outdated = false;
          fount_oit = true;
        }
        first_match = false;
        continue;
      } else {
        /* not first match, delete hash table entry,
         * mark tombstone only when oit is the most up-to-date entry */
        if (!fount_oit && item_info == oit_info) {
          fount_oit = true;
        }

        _item_free(bkt[i], !item_outdated);
        bkt[i] = 0;
      }
    }
    bkt_chain_len -= 1;
    bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
  } while (bkt_chain_len >= 0);

  unlock(first_bkt);

  return fount_oit;
}

bool
hashtable_delete_it(const char *oit_key, const uint32_t oit_klen,
                    const uint64_t seg_id, const uint64_t offset) {
  INCR(seg_metrics, hash_remove);

  uint64_t hv = CAL_HV(oit_key, oit_klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;

  uint64_t item_info;
  uint64_t oit_info = _build_item_info(tag, seg_id, offset);
  bool found_oit = false;

  lock(first_bkt);

  int bkt_chain_len = GET_BUCKET_CHAIN_LEN(first_bkt);
  int n_item_slot;
  do {
    n_item_slot = bkt_chain_len > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < n_item_slot; i++) {
      item_info = CLEAR_FREQ(bkt[i]);
      if (oit_info == CLEAR_FREQ(bkt[i])) {
        _item_free(item_info, false);
        bkt[i] = 0;
        found_oit = true;
        break;
      }
    }
    bkt_chain_len -= 1;
    bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
  } while (bkt_chain_len >= 0);

  unlock(first_bkt);

  return found_oit;
}

struct item *
hashtable_get(const char *key, const uint32_t klen, int32_t *seg_id,
              uint64_t *cas) {
  uint64_t hv = CAL_HV(key, klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;
  uint64_t offset;
  struct item *it;

  uint64_t item_info;

  int extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
  int array_size;

#ifdef USE_APFC
  uint64_t cur_ts = (uint64_t) time_proc_sec() & 0xfffful;
  if ( cur_ts != GET_TS(first_bkt)) {
      lock(first_bkt);

      if (cur_ts != GET_TS(first_bkt)) {
          *first_bkt = ((*first_bkt) & (~TS_MASK)) | (cur_ts << 32ul);
          do {
              array_size = extra_array_cnt > 0 ? N_SLOT_PER_BUCKET - 1 :
                                                 N_SLOT_PER_BUCKET;
              for (int i = 0; i < array_size; i++) {
                  if (bkt == first_bkt && i == 0) {
                      continue;
                  }
                  /* clear the bit */
                  bkt[i] = bkt[i] & 0xfff7fffffffffffful;

                  int old_freq = GET_FREQ(bkt[i]);
                  ASSERT(old_freq == GET_FREQ(bkt[i]) || old_freq - 128 == GET_FREQ(bkt[i]));
              }
              extra_array_cnt -= 1;
              bkt = (uint64_t *)(bkt[N_SLOT_PER_BUCKET - 1]);
          } while (extra_array_cnt >= 0);
      }

      unlock(first_bkt);

      bkt = first_bkt;
      extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
  }
#endif

  do {
    array_size = extra_array_cnt > 0 ? N_SLOT_PER_BUCKET - 1 :
                 N_SLOT_PER_BUCKET;

    for (int i = 0; i < array_size; i++) {
      if (bkt == first_bkt && i == 0) {
        continue;
      }

      item_info = bkt[i];
      if (GET_TAG(item_info) != tag) {
        continue;
      }
      /* a potential hit */
      if (!_same_item(key, klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }
      if (cas) {
        *cas = GET_CAS(first_bkt);
      }

      *seg_id = GET_SEG_ID(item_info);
      offset = GET_OFFSET(item_info);
      it = (struct item *) (heap.base + heap.seg_size * (*seg_id) + offset);

#ifdef USE_APFC
      uint64_t freq = GET_FREQ(item_info);

#if defined(SAMPLE_PER_SEC) && SAMPLE_PER_SEC == 1
//            if (it->freq < 16)
//                ASSERT(it->freq == freq || it->freq == freq - 128);

      if (freq < 127) {
          /* the highest bit of freq is not set
           * and add one does not overflow */
          if (freq <= 16 || prand() % freq == 0) {
              freq = ((freq + 1) | 0x80ul) << 44ul;
          } else {
              freq = (freq | 0x80ul) << 44ul;
          }
          {
              lock(first_bkt);
              if (bkt[i] == item_info) {
                  bkt[i] = (item_info & (~FREQ_MASK)) | freq;
              }
              unlock(first_bkt);
          }
      }
#else
      if (freq < 127) {
          if (freq <= 8 || prand() % freq == 0) {
              freq = ((freq + 1) | 0x80ul) << 44ul;
              lock(first_bkt);
              if (bkt[i] == item_info) {
                  bkt[i] = (item_info & (~FREQ_MASK)) | freq;
              }
              unlock(first_bkt);
          }
      }
#endif
#endif
      return it;
    }
    extra_array_cnt -= 1;
    bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
  } while (extra_array_cnt >= 0);

  return NULL;
}

struct item *
hashtable_get_no_incr(const char *key, const uint32_t klen, int32_t *seg_id,
                      uint64_t *cas) {
  uint64_t hv = CAL_HV(key, klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *bkt = first_bkt;
  uint64_t offset;
  struct item *it;

  /* 16-bit tag, 28-bit seg id, 20-bit offset (in the unit of 8-byte) */
  uint64_t item_info;

  int extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
  int array_size;
  do {
    array_size =
        extra_array_cnt > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < array_size; i++) {
      if (bkt == first_bkt && i == 0) {
        continue;
      }

      item_info = bkt[i];
      if (GET_TAG(item_info) != tag) {
        continue;
      }
      /* a potential hit */
      if (!_same_item(key, klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }
      if (cas) {
        *cas = GET_CAS(first_bkt);
      }

      *seg_id = GET_SEG_ID(item_info);
      offset = GET_OFFSET(item_info);
      it = (struct item *) (heap.base + heap.seg_size * (*seg_id) + offset);

      return it;
    }
    extra_array_cnt -= 1;
    bkt = (uint64_t *) (bkt[N_SLOT_PER_BUCKET - 1]);
  } while (extra_array_cnt >= 0);

  return NULL;
}

#ifdef USE_APFC
int hashtable_get_it_freq(const char *oit_key, const uint32_t oit_klen,
                      const uint64_t old_seg_id, const uint64_t old_offset)
{
    uint64_t hv = CAL_HV(oit_key, oit_klen);
    uint64_t tag = CAL_TAG_FROM_HV(hv);

    uint64_t *first_bkt = GET_BUCKET(hv);
    uint64_t *curr_bkt = first_bkt;
    uint64_t item_info;
    uint64_t oit_info = _build_item_info(tag, old_seg_id, old_offset);
    int freq = 0;

    int extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
    int array_size;
    do {
        array_size = extra_array_cnt > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

        for (int i = 0; i < array_size; i++) {
            if (curr_bkt == first_bkt && i == 0) {
                continue;
            }

            item_info = CLEAR_FREQ(curr_bkt[i]);
            if (GET_TAG(item_info) != tag) {
                continue;
            }

            if (item_info == oit_info) {
                freq = GET_FREQ(curr_bkt[i]) & 0x7Ful;
                return freq;
            }

            /* a potential hit */
            if (!_same_item(oit_key, oit_klen, item_info)) {
                INCR(seg_metrics, hash_tag_collision);
                continue;
            }

            /* the oit is outdated */
            return 0;

        }
        extra_array_cnt -= 1;
        curr_bkt = (uint64_t *)(curr_bkt[N_SLOT_PER_BUCKET - 1]);
    } while (extra_array_cnt >= 0);

    /* disable this because an item can be evicted by other threads */
//    ASSERT(0);
    return 0;
}
#endif


/*
 * relink is used when the item is moved from one segment to another
 *
 * a few caveats
 *  item being relinked could be outdated, in which case we should not relink
 *
 * TODO(jason): it might be better not clear those old entries?
 */
bool
hashtable_relink_it(const char *oit_key, const uint32_t oit_klen,
                    const uint64_t old_seg_id, const uint64_t old_offset,
                    const uint64_t new_seg_id, const uint64_t new_offset) {
  INCR(seg_metrics, hash_remove);

  uint64_t hv = CAL_HV(oit_key, oit_klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *curr_bkt = first_bkt;
  uint64_t item_info;
  bool item_outdated = true, first_match = true;

  uint64_t oit_info = _build_item_info(tag, old_seg_id, old_offset);
  uint64_t nit_info = _build_item_info(tag, new_seg_id, new_offset);

  lock(first_bkt);

  int bkt_chain_len = GET_BUCKET_CHAIN_LEN(first_bkt);
  int array_size;
  do {
    array_size = bkt_chain_len > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < array_size; i++) {
      if (curr_bkt == first_bkt && i == 0) {
        continue;
      }

      item_info = CLEAR_FREQ(curr_bkt[i]);
      if (GET_TAG(item_info) != tag) {
        continue;
      }

      /* a potential hit */
      if (!_same_item(oit_key, oit_klen, item_info)) {
        INCR(seg_metrics, hash_tag_collision);
        continue;
      }

      if (first_match) {
        if (oit_info == item_info) {
          /* item is not outdated */
          curr_bkt[i] = nit_info;
          item_outdated = false;
        }
        first_match = false;
        continue;
      }

      /* not first match, delete */
      _item_free(curr_bkt[i], false);
      curr_bkt[i] = 0;
    }
    bkt_chain_len -= 1;
    curr_bkt = (uint64_t *) (curr_bkt[N_SLOT_PER_BUCKET - 1]);
  } while (bkt_chain_len >= 0);

  unlock(first_bkt);

  return !item_outdated;
}

bool
hashtable_check_it(const char *oit_key, const uint32_t oit_klen,
                   const uint64_t seg_id, const uint64_t offset) {
  INCR(seg_metrics, hash_remove);

  uint64_t hv = CAL_HV(oit_key, oit_klen);
  uint64_t tag = CAL_TAG_FROM_HV(hv);
  uint64_t *first_bkt = GET_BUCKET(hv);
  uint64_t *curr_bkt = first_bkt;

  uint64_t oit_info = _build_item_info(tag, seg_id, offset);

  lock(first_bkt);

  int extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
  int array_size;
  do {
    array_size =
        extra_array_cnt > 0 ? N_SLOT_PER_BUCKET - 1 : N_SLOT_PER_BUCKET;

    for (int i = 0; i < array_size; i++) {
      if (oit_info == curr_bkt[i]) {
        unlock(first_bkt);
        return true;
      }
    }
    extra_array_cnt -= 1;
    curr_bkt = (uint64_t *) (curr_bkt[N_SLOT_PER_BUCKET - 1]);
  } while (extra_array_cnt >= 0);

  unlock(first_bkt);

  return false;
}

void
hashtable_stat(int *item_cnt_ptr, int *extra_array_cnt_ptr) {
#define BUCKET_HEAD(idx) (&hash_table.table[(idx)*N_SLOT_PER_BUCKET])

  int item_cnt = 0;
  int extra_array_cnt_sum = 0, extra_array_cnt;
  uint64_t item_info;
  uint64_t *first_bkt, *curr_bkt;
  int array_size;
  int n_bucket = HASHSIZE(hash_table.hash_power - N_SLOT_PER_BUCKET_IN_BITS);

  for (uint64_t bucket_idx = 0; bucket_idx < n_bucket; bucket_idx++) {
    first_bkt = BUCKET_HEAD(bucket_idx);
    curr_bkt = first_bkt;
    extra_array_cnt = GET_BUCKET_CHAIN_LEN(first_bkt);
    extra_array_cnt_sum += extra_array_cnt;
    do {
      array_size = extra_array_cnt >= 1 ? N_SLOT_PER_BUCKET - 1 :
                   N_SLOT_PER_BUCKET;

      for (int i = 0; i < array_size; i++) {
        if (curr_bkt == first_bkt && i == 0) {
          continue;
        }

        item_info = curr_bkt[i];
        if (item_info != 0) {
          item_cnt += 1;
        }
      }
      extra_array_cnt -= 1;
      curr_bkt = (uint64_t *) (curr_bkt[N_SLOT_PER_BUCKET - 1]);
    } while (extra_array_cnt >= 0);
  }

  if (item_cnt_ptr != NULL) {
    *item_cnt_ptr = item_cnt;
  }
  if (extra_array_cnt_ptr != NULL) {
    *extra_array_cnt_ptr = extra_array_cnt_sum;
  }

  log_info("hashtable %d entries, %d extra_arrays", item_cnt,
           extra_array_cnt_sum);

#undef BUCKET_HEAD
}

void
scan_hashtable_find_seg(int32_t target_seg_id) {
#define BUCKET_HEAD(idx) (&hash_table.table[(idx)*N_SLOT_PER_BUCKET])
  log_warn("expensive debug");

  int extra_array_cnt;
  uint64_t item_info;
  uint64_t *bucket, *array;
  int array_size;
  uint64_t seg_id;
  uint64_t offset;
  struct item *it;
  int n_bucket = HASHSIZE(hash_table.hash_power - N_SLOT_PER_BUCKET_IN_BITS);

  for (uint64_t bucket_idx = 0; bucket_idx < n_bucket; bucket_idx++) {
    bucket = BUCKET_HEAD(bucket_idx);
    array = bucket;
    extra_array_cnt = GET_BUCKET_CHAIN_LEN(bucket);
    int extra_array_cnt0 = extra_array_cnt;
    do {
      array_size = extra_array_cnt >= 1 ? N_SLOT_PER_BUCKET - 1 :
                   N_SLOT_PER_BUCKET;

      for (int i = 0; i < array_size; i++) {
        if (array == bucket && i == 0) {
          continue;
        }

        item_info = array[i];

        if (item_info == 0) {
          continue;
        }

        seg_id = ((item_info & SEG_ID_MASK) >> 20u);
        if (target_seg_id == seg_id) {
          offset = (item_info & OFFSET_MASK) << 3u;
          it = (struct item *) (heap.base + heap.seg_size * seg_id +
              offset);
          log_warn("find item (%.*s) len %d on seg %d offset %d, item_info "
                   "%lu, i %d, extra %d %d",
                   it->klen,
                   item_key(it),
                   it->klen,
                   seg_id,
                   offset,
                   item_info,
                   i,
                   extra_array_cnt0,
                   extra_array_cnt);
          ASSERT(0);
        }
      }
      extra_array_cnt -= 1;
      array = (uint64_t *) (array[N_SLOT_PER_BUCKET - 1]);
    } while (extra_array_cnt >= 0);
  }

#undef BUCKET_HEAD
}










static inline cache_obj_t *chained_hashtable_find_obj_id(hashtable_t *hashtable,
                                                         obj_id_t obj_id) {
  cache_obj_t *cache_obj, *ret = NULL;
  uint64_t hv = get_hash_value_int_64(&obj_id);
  hv = hv & hashmask(hashtable->hashpower);
  cache_obj = &hashtable->table[hv];
  if (OBJ_EMPTY(cache_obj)) {
    // the object does not exist
    return NULL;
  }

  int depth = 0;
  while (cache_obj) {
    depth += 1;
    if (cache_obj->obj_id == obj_id) {
      ret = cache_obj;
      break;
    }
    cache_obj = cache_obj->hash_next;
  }
//  if (depth > 6){
//    printf("depth %d size %d %d\n", depth, hashtable->n_cur_item, hashsize(hashtable->hashpower));
//  }
  return ret;
}

cache_obj_t *chained_hashtable_find(hashtable_t *hashtable, request_t *req) {
  cache_obj_t *cache_obj, *ret = NULL;
  uint64_t hv;

  if (req->hv == 0) {
    hv = get_hash_value_int_64(&req->obj_id);
    req->hv = hv;
  } else {
    hv = req->hv;
  }

  hv = hv & hashmask(hashtable->hashpower);
  cache_obj = &hashtable->table[hv];
  if (OBJ_EMPTY(cache_obj)) {
    // the object does not exist
    return NULL;
  }

  int depth = 0;
  while (cache_obj) {
    depth += 1;
    if (cache_obj->obj_id == req->obj_id) {
      ret = cache_obj;
      break;
    }
    cache_obj = cache_obj->hash_next;
  }

//  if (depth > 8) {
//    printf("pos %lu, depth %d\n", (unsigned long) hv, depth);
//  }

  return ret;
}

cache_obj_t *chained_hashtable_find_obj(hashtable_t *hashtable,
                                        cache_obj_t *obj_to_find) {
  return chained_hashtable_find_obj_id(hashtable, obj_to_find->obj_id);
}

cache_obj_t *chained_hashtable_insert(hashtable_t *hashtable, request_t *req) {
}

/* you need to free the extra_metadata before deleting from hash table */
void chained_hashtable_delete(hashtable_t *hashtable, cache_obj_t *cache_obj) {
  hashtable->n_cur_item -= 1;
  uint64_t hv = get_hash_value_int_64(&cache_obj->obj_id)
      & hashmask(hashtable->hashpower);
  cache_obj_t *cache_obj_in_bucket = &hashtable->table[hv];
  assert(!OBJ_EMPTY(cache_obj_in_bucket));
  if (cache_obj == cache_obj_in_bucket) {
    if (cache_obj_in_bucket->hash_next) {
      cache_obj_t *old_obj = cache_obj_in_bucket->hash_next;
      cache_obj_t *new_obj = cache_obj_in_bucket;
      _move_obj_to_new_loc(hashtable, new_obj, old_obj);
      free_cache_obj(old_obj);
    } else {
      delete_obj_in_table(hashtable, cache_obj_in_bucket);
      memset(cache_obj_in_bucket, 0, sizeof(cache_obj_t));
    }
  } else {
    cache_obj_t *prev_cache_obj = NULL;
    while (cache_obj_in_bucket) {
      prev_cache_obj = cache_obj_in_bucket;
      cache_obj_in_bucket = cache_obj_in_bucket->hash_next;
      if (cache_obj_in_bucket == cache_obj) {
        prev_cache_obj->hash_next = cache_obj->hash_next;
        delete_obj_in_table(hashtable, cache_obj);
//        memset(cache_obj, 0, sizeof(cache_obj_t));
        free_cache_obj(cache_obj);
        break;
      }
    }
    assert(cache_obj_in_bucket != NULL);
  }
}

cache_obj_t *chained_hashtable_rand_obj(hashtable_t *hashtable) {
  uint64_t pos = next_rand() & hashmask(hashtable->hashpower);
  while (OBJ_EMPTY(&hashtable->table[pos])) {
    pos = (pos + 1) & hashmask(hashtable->hashpower);
  }
  return &hashtable->table[pos];
}

void chained_hashtable_foreach(hashtable_t *hashtable,
                               hashtable_iter iter_func,
                               void *user_data) {
  cache_obj_t *cur_obj;
  for (uint64_t i = 0; i < hashsize(hashtable->hashpower); i++) {
    if (OBJ_EMPTY(&hashtable->table[i]))
      continue;

    cur_obj = &hashtable->table[i];
    iter_func(cur_obj, user_data);
    while (cur_obj->hash_next) {
      cur_obj = cur_obj->hash_next;
      iter_func(cur_obj, user_data);
    }
  }
}


/* grows the hashtable to the next power of 2. */
void _chained_hashtable_expand(hashtable_t *hashtable) {
  INFO("chained hash table expand to hash power %d\n", hashtable->hashpower+1);

  cache_obj_t *old_table = hashtable->table;
  hashtable->table =
      my_malloc_n(cache_obj_t, hashsize(++hashtable->hashpower));
  memset(hashtable->table,
         0,
         hashsize(hashtable->hashpower) * sizeof(cache_obj_t));
#ifdef USE_HUGEPAGE
  madvise(hashtable->table, sizeof(cache_obj_t)*hashsize(hashtable->hashpower), MADV_HUGEPAGE);
#endif
  ASSERT_NOT_NULL(hashtable->table,
                  "unable to grow hashtable to size %llu\n",
                  hashsizeULL(hashtable->hashpower));

  // move from old table into new hash table
  cache_obj_t *cur_obj, *next_obj;
  for (uint64_t i = 0; i < hashsize((hashtable->hashpower - 1)); i++) {
    if (OBJ_EMPTY(&old_table[i]))
      continue;

    cur_obj = &old_table[i];
    next_obj = cur_obj->hash_next;
    _move_into_new_table(hashtable, cur_obj, true);
    while (next_obj) {
      cur_obj = next_obj;
      next_obj = cur_obj->hash_next;
      _move_into_new_table(hashtable, cur_obj, false);
    }
  }
  my_free(sizeof(cache_obj_t) * hashsize(hashtable->hashpower - 1), old_table);
  VERBOSE("hashtable resized from %llu to %llu\n",
          hashsizeULL((uint16_t) (hashtable->hashpower - 1)),
          hashsizeULL(hashtable->hashpower));
}


#ifdef __cplusplus
}
#endif
